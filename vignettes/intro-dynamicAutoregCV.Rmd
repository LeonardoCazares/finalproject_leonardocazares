---
title: "Introduction to dynamicAutoregCV"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to dynamicAutoregCV}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Firstly, all the necessary libraries, for the autoregression model and plots are imported.

```{r setup}
library(dynamicAutoregCV)
library(ggplot2)
```

As a use case, we work with a dataset of average daily temperature in Austin, TX. These data were extracted from the National Centers for Environmental Information (NCEI) [website](https://www.ncei.noaa.gov). 

The dataset covers the period from 2016-01-01 to 2025-08-25, with measurements in °F. As part of the data preprocessing, all NaN values were replaced with the last valid temperature measurement so that the autoregressive model is not biased by future (out-of-sample) measurements.

```{r load-data}
data("temp_austin")
str(temp_austin)
head(temp_austin)
```

From the above code we will only keep the univariate time-series of interest and the dates. 

```{r plot data}
temps <- temp_austin$temp
temp_austin$date <- as.Date(temp_austin$date) # Keep dates as Date data-type
dates <- temp_austin$date

summary(temps)
```

Showing the available data in the next plot.

```{r plot-time-series, fig.height=4, fig.width=7}
ggplot(temp_austin, aes(x = date, y = temp)) +
  geom_line() +
  labs(
    title = "Daily temperature in Austin",
    x = "Date",
    y = "Temperature (°F)"
  ) +
  theme_minimal()
```

As we can see there is a gap in the data corresponding to the 2020 year, the temperature measurements from that year where removed because most of the half of the where not available (NaNs values).

```{r split data}
train_test_data <- train_test_split(temps, dates, p = 0.05)
print(paste('The total lenght of the time-serie is:', length(temps)))
print(paste('The number of points for cross-validation (and initial training) are:', length(train_test_data$x_train)))
print(paste('The number of points for testing (and dynamic training) are:',length(train_test_data$x_test)))
print(paste('Initial date for training', train_test_data$dates_train[1], '. Final date for training', train_test_data$dates_train[length(train_test_data$dates_train)]))
print(paste('Initial date for testing', train_test_data$dates_test[1], '. Final date for testing', train_test_data$dates_test[length(train_test_data$dates_test)]))
```

First and foremost, we can complete the cross-validation procedure. For this task, we define two grids, one for the beta values and the other for the number of lags, over which we perform the blocked cross-validation scheme ([Schnaubelt M., 2019](https://www.econstor.eu/bitstream/10419/209136/1/1684440068.pdf)) across all possible combinations of the hyperparameters, selecting the one that minimizes the out-of-sample prediction error.

```{r cross-validation}
betas <- c(0.0001, 0.001, 0.01, 0.1, 0.25, 0.5, 0.75, 1, 2.5, 5, 10, 20, 50)

lags <- c(3,7,14,21,30)

beta_min <- NULL
lag_min <- NULL
mean_mae_min <- Inf

for (lag_i in lags){
  for (beta_i in betas){
    cv_beta_i <- cv_ar_l2(train_test_data$x_train, folds = 8, # 8
                          lags = lag_i, beta = beta_i)$mean_mae
    if (cv_beta_i < mean_mae_min){
      mean_mae_min <- cv_beta_i
      beta_min <- beta_i
      lag_min <- lag_i
    }
  }
}

cat(
  "The lowest mean out-of-sample prediction error was achieved while,\n",
  "beta = ", beta_min, "\n",
  "lags = ", lag_min, "\n",
  "Min. RMSE = ", mean_mae_min, "\n",
  sep = ""
)

```

At this point we have the optimized regularization parameter and the number of lags, from this point forward we create the predictions with dynamic training, evaluating the performance of our model with the RMSE.

```{r dynamic training}
forecasting <- dynamic_regression(train_test_data$x_train,
                   train_test_data$x_test,
                   beta_min, lag_min, window = 365)

rmse_value <- rmse(train_test_data$x_test,
             forecasting)

print(paste('The RMSE = ', rmse_value))
```

Below we can appreciate the behavior of the ground-truth prediction and the predictions given by the dynamic autoregressive model with ridge regularization.

```{r GT vs. Forecasting, fig.height=4, fig.width=7}
initial_test_date <- train_test_data$dates_test[1]
final_test_date <- train_test_data$dates_test[length(train_test_data$dates_test)]

df_plot <- data.frame(
  date   = rep(train_test_data$dates_test, 2),
  value  = c(train_test_data$x_test, forecasting),
  serie  = rep(c("Ground-Truth", "Forecasting"), each = length(train_test_data$dates_test))
)

ggplot(df_plot, aes(x = date, y = value, color = serie)) +
  geom_line() +
  scale_color_manual(values = c("Ground-Truth" = "black", "Forecasting" = "red")) +
  labs(title = paste('Ground-Truth vs. Forecasting for Temperature in Austin, TX. ',initial_test_date,' - ',final_test_date),
       x = "Date",
       y = "Temperature (°F)",
       color = "Time serie:") +
  theme_minimal()
```

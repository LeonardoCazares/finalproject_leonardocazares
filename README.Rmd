---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# dynamicAutoregCV

<!-- badges: start -->
<!-- badges: end -->

## Objective

The goal of dynamicAutoregCV is to create a linear ridge autoregression algorithm for time-series forecasting with dynamic training. The main features of the package include:

- A cross-validation scheme that allows us to find the best regularization parameter (for ridge regression) and the number of lags considered for the autogressive settings.

![Figure 1. Cross-validation for time series.](man/figures/rep_comp_project.jpeg)

<p></p>

- Dynamic forecasting for the test set, moving forward the training window training epoch.

![Figure 2. Time series out-of-sample forecasting.](man/figures/forecasting.jpg)

## Data

To acomplish the two features mentioned above we prepared a dataset of average daily temperature in Austin, TX (extracted from the National Centers for Environmental Information [NCEI](https://www.ncei.noaa.gov)). The dataset covers the period from 2016-01-01 to 2025-08-25, with measurements in °F (see Figure 1). 

## Functions

Below the functions created for this projects are showed, followed by a simple code sample displaying the main functionalities of each function:

### `train_test_split()`
Splits a univariate time series into training and testing sets based on a percentage cutoff.

```{r, eval=FALSE}
train_test_data <- train_test_split(x, # Total time serie
                                    dates, # Total dates
                                    p = 0.05) # Proportion for testing
train_test_data$x_train # Training dataset
train_test_data$x_test # Testing dataset
train_test_data$dates_train # Training dates
train_test_data$dates_test # Testing dates
```

### `cv_dataset_creation()`
Given the training dataset creates the folds for the blocked cross-validation squeme ([Schnaubelt M., 2019](https://www.econstor.eu/bitstream/10419/209136/1/1684440068.pdf)).

```{r, eval=FALSE}
cv_datasets <- cv_dataset_creation(train_test_data$x_train, # Training data for CV
                                   folds = 5) # Number of folds
result$fold_1 # List containing training and validation datasets for the first CV iteration
```

### `fit_ar_l2()`
Fits an autoregressive model with L2 (ridge) regularization.  
Takes a univariate time series and a set of lags, solves the closed-form ridge estimator, and returns fitted values, coefficients, and error metrics.

```{r, eval=FALSE}
fit <- fit_ar_l2(x_train, # Training data
                 lags = lags, # Number of lags
                 beta = beta) # Ridge. reg. parameter
fit$coef # Regression coefficients (penalized by ridge reg.)
```

### `cv_ar_l2()`
Performs K-fold blocked cross-validation  ([Schnaubelt M., 2019](https://www.econstor.eu/bitstream/10419/209136/1/1684440068.pdf)) over a grid of regularization parameters and/or lag values.  
Returns the mean validation error for each combination and identifies the optimal hyperparameters.

```{r, eval=FALSE}
cv_results <- cv_ar_l2(x_train, # Training dataset
                       folds = 9, # Number of folds
                       lags = 7, # Number of lags
                       beta = 0.1) # Ridge. reg. parameter
cv_results$mean_mae # Mean RMSE over all folds in the blocked CV.
```

### `dynamic_regression()`
Implements dynamic (rolling-window) training and forecasting.  
At each time step, the model is re-trained using only the most recent observations in a sliding window.  
Returns rolling predictions, error metrics, and the model sequence.

```{r, eval=FALSE}
forecasting <- dynamic_regression(x_train, # Training dataset
                                  x_test, # Testing dataset
                                  beta = 0.1, # Ridge. reg. parameter
                                  lags = 7, # Number of lags
                                  window = 365) # Sliding window model training
forecasting # Out-of-sample predictions/forecasting
```

### `rmse()`
Computes the Root Mean Squared Error (RMSE) between the ground-truth time serie and the forecasting.

```{r, eval=FALSE}
error <- rmse(x_test, # Ground-truth time-serie
                    forecasting) # Forecasting
error # RMSE between x_test and forecasting
```

## Installation

You can install the development version of dynamicAutoregCV from [GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("LeonardoCazares/finalproject_leonardocazares")
```

## References

- S. Yang, M. Santillana, & S.C. Kou, Accurate estimation of influenza epidemics using Google search data via ARGO, Proc. Natl. Acad. Sci. U.S.A. 112 (47) 14473-14478, https://doi.org/10.1073/pnas.1515373112 (2015).
- Schnaubelt, M. (2019). A comparison of machine learning model validation schemes for non-stationary time series data (FAU Discussion Papers in Economics, No. 11/2019). Friedrich-Alexander University Erlangen–Nuremberg, Institute for Economics. https://hdl.handle.net/10419/209136.

## Work to be done...

- [EXTRA] If possible, apply a conformal prediction algorithm for the uncertainty quantification of the time-series forecasts.

